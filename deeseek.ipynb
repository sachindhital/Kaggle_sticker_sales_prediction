{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\sachi\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Collecting holidays\n",
      "  Using cached holidays-0.65-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\sachi\\appdata\\roaming\\python\\python312\\site-packages (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sachi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached holidays-0.65-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: holidays\n",
      "Successfully installed holidays-0.65\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy holidays scikit-learn lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load data\n",
    "train = pd.read_csv('train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Handle Missing Values\n",
    "# Impute missing target values using group median\n",
    "train['num_sold'] = train.groupby(['country', 'store', 'product'])['num_sold'] \\\n",
    "                       .transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Add Basic Date Features\n",
    "for df in [train, test]:\n",
    "    # Weekend feature\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['dayofweek'] >= 5).astype('int8')\n",
    "    \n",
    "    # Month/year features\n",
    "    df['month'] = df['date'].dt.month.astype('int8')\n",
    "    df['year'] = df['date'].dt.year.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Add Holiday Features\n",
    "country_holidays = {\n",
    "    'Canada': holidays.CA(years=range(2010, 2021)),\n",
    "    'Finland': holidays.FI(years=range(2010, 2021)),\n",
    "    'Italy': holidays.IT(years=range(2010, 2021)),\n",
    "    'Kenya': holidays.KE(years=range(2010, 2021)),\n",
    "    'Norway': holidays.NO(years=range(2010, 2021)),\n",
    "    'Singapore': holidays.SG(years=range(2010, 2021))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n",
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\2250723065.py:5: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')\n"
     ]
    }
   ],
   "source": [
    "for df in [train, test]:\n",
    "    df['is_holiday'] = 0\n",
    "    for country, cal in country_holidays.items():\n",
    "        country_mask = df['country'] == country\n",
    "        df.loc[country_mask, 'is_holiday'] = df.loc[country_mask, 'date'].isin(cal).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Add Seasonality Features\n",
    "for df in [train, test]:\n",
    "    # Yearly seasonality\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear.astype('int16')\n",
    "    df['year_sin'] = np.sin(2 * np.pi * df['dayofyear']/365).astype('float32')\n",
    "    df['year_cos'] = np.cos(2 * np.pi * df['dayofyear']/365).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Memory-Efficient Lag Features\n",
    "# Process training data in groups\n",
    "def add_lags(group):\n",
    "    group = group.sort_values('date')\n",
    "    for lag in [7, 14, 28]:  # 1, 2, 4 weeks\n",
    "        group[f'lag_{lag}'] = group['num_sold'].shift(lag).astype('float32')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\3164603853.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train = train.groupby(['country', 'store', 'product'], group_keys=False).apply(add_lags)\n"
     ]
    }
   ],
   "source": [
    "train = train.groupby(['country', 'store', 'product'], group_keys=False).apply(add_lags)\n",
    "\n",
    "# Get last lag values for test data\n",
    "last_lags = train.groupby(['country', 'store', 'product']).last().reset_index()\n",
    "test = test.merge(last_lags[['country', 'store', 'product', 'lag_7', 'lag_14', 'lag_28']],\n",
    "                 on=['country', 'store', 'product'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: Optimized Rolling Features\n",
    "def add_rolling(group):\n",
    "    group = group.sort_values('date')\n",
    "    for window in [7, 28]:  # 1 week and 4 weeks\n",
    "        group[f'rolling_{window}'] = group['num_sold'].shift(1).rolling(window, min_periods=1).mean().astype('float32')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\AppData\\Local\\Temp\\ipykernel_23320\\3218172841.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train = train.groupby(['country', 'store', 'product'], group_keys=False).apply(add_rolling)\n"
     ]
    }
   ],
   "source": [
    "train = train.groupby(['country', 'store', 'product'], group_keys=False).apply(add_rolling)\n",
    "\n",
    "# Get last rolling values for test data\n",
    "last_rolling = train.groupby(['country', 'store', 'product']).last().reset_index()\n",
    "test = test.merge(last_rolling[['country', 'store', 'product', 'rolling_7', 'rolling_28']],\n",
    "                 on=['country', 'store', 'product'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Fill Remaining NAs\n",
    "for col in ['lag_7', 'lag_14', 'lag_28', 'rolling_7', 'rolling_28']:\n",
    "    test[col] = test[col].fillna(test[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Encode Categorical Features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in ['country', 'store', 'product']:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([train[col], test[col]])\n",
    "    le.fit(combined)\n",
    "    train[col] = le.transform(train[col]).astype('int8')\n",
    "    test[col] = le.transform(test[col]).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10: Prepare Features\n",
    "features = [\n",
    "    'year', 'month', 'dayofweek', 'is_weekend', 'is_holiday',\n",
    "    'year_sin', 'year_cos', \n",
    "    'lag_7', 'lag_14', 'lag_28',\n",
    "    'rolling_7', 'rolling_28',\n",
    "    'country', 'store', 'product'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = np.log1p(train['num_sold'])  # Log transform\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 11: Train Model\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import lightgbm as lgb\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1755\n",
      "[LightGBM] [Info] Number of data points in the train set: 57534, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 5.740918\n",
      "Fold 1 trained\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1757\n",
      "[LightGBM] [Info] Number of data points in the train set: 115066, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 5.768754\n",
      "Fold 2 trained\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1751\n",
      "[LightGBM] [Info] Number of data points in the train set: 172598, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 5.778026\n",
      "Fold 3 trained\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='mape',\n",
    "        num_leaves=31,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=0)]\n",
    "    )\n",
    "    models.append(model)\n",
    "    print(f\"Fold {fold+1} trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 12: Generate Predictions\n",
    "test_preds = np.mean([model.predict(X_test) for model in models], axis=0)\n",
    "final_pred = np.expm1(test_preds)  # Convert from log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'num_sold': final_pred\n",
    "})\n",
    "submission.to_csv('submissiondeep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
